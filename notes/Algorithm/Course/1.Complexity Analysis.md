---
title: "Complexity Analysis"
author: "SanWang"
date: "2021-09-17"
---
## Why?

Shortcomings of empirical metrics:

1. Its result depends on the platform(computer, programming language, etc.). But algorithms are *platform-independent*.
2. Its result also depends on the *input-size* of the data.

## Big O Notation

Represents the *asymptotic upper bound* of a function.

### Properties

#### 1. Sum

if
$$
    T_1(n) = O(g(n)),
    T_2(n) = O(f(n)),
$$
then
$$
    T_1(n) + T_2(n) = max(O(g(n)), O(f(n))) = O(max(g(n), f(n))).
$$

#### 2. Product

$$
    T_1(n) * T_2(n) = O(g(n)) *O(f(n))) = O(g(n)* f(n))
$$

## Common Time Complexities

> - An algorithm is said to have **polynomial time complexity**, if its worst case is bounded by a polynomial $p(n)$.
> - Another type of complexity class is NP(nondeterministic polynomial).

| Running Time | Name | Example |
| ----|------| ----|
|  $o(1)$  | constant time |  |
| $O(n)$ | linear time |  |
| $O(logn)$ | logarithmic time | Binary Search |
| $O(nlogn)$ | linearithmic time |  |
| $O(n^2)$ | quadratic time | Bubble Sort, Insertion Sort |
| $O(n^3)$ | cubic time |  |
| $2^{O(logn)} = poly(n) = n^{O(1)}$ | polynomial time |  |

## Space Complexity

Normally $O(1)$, $O(n)$, $O(n^2)$, etc. without logarithm.

## Complexity

### 1. Best-case Complexity

To describe an algorithm's behavior under optimal conditions.

### 2. Worst-case Complexity

### 3. Average-case Complexity

The amount of some computational resouces used by the algorithm, averaged over all possible inputs.

## Amortized Analysis

To look at the worst-case run time per operation rather than per algorithm.
> The basic idea is that a worst-case operation can alter the state in a way that the worst case cannot occur again for a long time, thus "amortizing" its cost.
